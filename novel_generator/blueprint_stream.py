# novel_generator/blueprint_stream.py
# -*- coding: utf-8 -*-
"""
æ”¯æŒæµå¼è¾“å‡ºçš„ç« èŠ‚è“å›¾ç”Ÿæˆ
"""
import os
import re
import logging
from novel_generator.blueprint import (
    compute_chunk_size, 
    limit_chapter_blueprint, 
    parse_blueprint_blocks,
    _interleave_units_and_chapters,
    validate_and_fix_cultivation_progression,
    validate_chapter_continuity,
    track_foreshadowing,
    validate_spatial_coordinates
)
from llm_adapters import create_llm_adapter
from prompt_definitions import chunked_chapter_blueprint_prompt, unit_generation_prompt
from utils import read_file, clear_file_content, save_string_to_txt


def invoke_with_streaming(llm_adapter, prompt: str, stream_callback: callable = None) -> str:
    """
    è°ƒç”¨LLMç”Ÿæˆå†…å®¹ï¼Œæ”¯æŒæµå¼è¾“å‡º

    å‚æ•°:
        llm_adapter: LLMé€‚é…å™¨
        prompt: æç¤ºè¯
        stream_callback: æµå¼è¾“å‡ºå›è°ƒå‡½æ•°

    è¿”å›:
        str: å®Œæ•´çš„ç”Ÿæˆç»“æœ
    """
    result = ""

    try:
        if hasattr(llm_adapter, 'invoke_stream'):
            result = llm_adapter.invoke_stream(prompt, stream_callback if stream_callback else lambda x: None)
        else:
            result = llm_adapter.invoke(prompt)
            if stream_callback:
                chunk_size = 100
                for i in range(0, len(result), chunk_size):
                    chunk = result[i:i+chunk_size]
                    stream_callback(chunk)
    except Exception as e:
        logging.error(f"Error during streaming: {e}")
        try:
            result = llm_adapter.invoke(prompt)
            if stream_callback:
                chunk_size = 100
                for i in range(0, len(result), chunk_size):
                    chunk = result[i:i+chunk_size]
                    stream_callback(chunk)
        except Exception as e2:
            logging.error(f"Error during fallback invoke: {e2}")
            result = ""

    return result


def generate_units_for_range_stream(
    llm_adapter,
    architecture_text: str,
    existing_blueprint: str,
    start_chapter: int,
    end_chapter: int,
    number_of_chapters: int,
    user_guidance: str,
    world_building: str,
    stream_callback: callable = None
) -> str:
    """
    ä¸ºæŒ‡å®šç« èŠ‚èŒƒå›´ç”Ÿæˆå•å…ƒä¿¡æ¯ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰

    å‚æ•°:
        llm_adapter: LLMé€‚é…å™¨
        architecture_text: å°è¯´æ¶æ„æ–‡æœ¬
        existing_blueprint: å·²æœ‰ç›®å½•æ–‡æœ¬
        start_chapter: èµ·å§‹ç« èŠ‚å·
        end_chapter: ç»“æŸç« èŠ‚å·
        number_of_chapters: æ€»ç« èŠ‚æ•°
        user_guidance: ç”¨æˆ·æŒ‡å¯¼
        world_building: ä¸–ç•Œè§‚
        stream_callback: æµå¼è¾“å‡ºå›è°ƒå‡½æ•°

    è¿”å›:
        str: ç”Ÿæˆçš„å•å…ƒä¿¡æ¯
    """
    # é™åˆ¶å·²æœ‰ç›®å½•ä¸ºæœ€è¿‘100ç« 
    limited_blueprint = limit_chapter_blueprint(existing_blueprint, 100)

    # æ„å»ºå•å…ƒç”Ÿæˆæç¤ºè¯
    unit_prompt = unit_generation_prompt.format(
        novel_architecture=architecture_text,
        chapter_list=limited_blueprint,
        number_of_chapters=number_of_chapters,
        n=start_chapter,
        m=end_chapter,
        user_guidance=user_guidance,
        world_building=world_building
    )

    logging.info(f"Generating units for chapters [{start_chapter}..{end_chapter}]...")

    # é€šçŸ¥å¼€å§‹ç”Ÿæˆå•å…ƒ
    if stream_callback:
        stream_callback("\n\n========== ã€ç¬¬ä¸€é˜¶æ®µï¼šç”Ÿæˆå•å…ƒä¿¡æ¯ã€‘ ==========\n\n")

    # ç”Ÿæˆå•å…ƒä¿¡æ¯ï¼ˆå¸¦æµå¼è¾“å‡ºï¼‰
    unit_result = invoke_with_streaming(llm_adapter, unit_prompt, stream_callback)

    if not unit_result or not unit_result.strip():
        error_msg = f"å•å…ƒ [{start_chapter}..{end_chapter}] ç”Ÿæˆå¤±è´¥ï¼šè¿”å›å†…å®¹ä¸ºç©º"
        logging.error(error_msg)
        raise ValueError(error_msg)

    # æ¸…ç†ç”Ÿæˆçš„å•å…ƒä¿¡æ¯
    cleaned_result = unit_result.strip()
    if cleaned_result.startswith("##"):
        cleaned_result = cleaned_result[2:].lstrip()
    while cleaned_result.startswith("\n"):
        cleaned_result = cleaned_result[1:]

    # é€šçŸ¥å•å…ƒç”Ÿæˆå®Œæˆ
    if stream_callback:
        stream_callback("\n\n========== ã€å•å…ƒä¿¡æ¯ç”Ÿæˆå®Œæˆã€‘ ==========\n\n")

    return cleaned_result


def Chapter_blueprint_generate_range_stream(
    interface_format: str,
    api_key: str,
    base_url: str,
    llm_model: str,
    filepath: str,
    start_chapter: int,
    end_chapter: int,
    number_of_chapters: int,
    user_guidance: str = "",
    generation_requirements: str = "",
    temperature: float = 0.7,
    max_tokens: int = 4096,
    timeout: int = 600,
    stream_callback: callable = None
) -> None:
    """
    ç”ŸæˆæŒ‡å®šç« èŠ‚èŒƒå›´çš„ç›®å½•ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰

    å‚æ•°:
        interface_format: æ¥å£æ ¼å¼
        api_key: APIå¯†é’¥
        base_url: APIåŸºç¡€URL
        llm_model: æ¨¡å‹åç§°
        filepath: å°è¯´ç›®å½•è·¯å¾„
        start_chapter: èµ·å§‹ç« èŠ‚å·
        end_chapter: ç»“æŸç« èŠ‚å·
        number_of_chapters: æ€»ç« èŠ‚æ•°
        user_guidance: ç”¨æˆ·æŒ‡å¯¼
        generation_requirements: ç”Ÿæˆè¦æ±‚
        temperature: æ¸©åº¦å‚æ•°
        max_tokens: æœ€å¤§tokenæ•°
        timeout: è¶…æ—¶æ—¶é—´
        stream_callback: æµå¼è¾“å‡ºå›è°ƒå‡½æ•°
    """
    arch_file = os.path.join(filepath, "Novel_architecture.txt")
    if not os.path.exists(arch_file):
        logging.warning("Novel_architecture.txt not found. Please generate architecture first.")
        return

    architecture_text = read_file(arch_file).strip()
    if not architecture_text:
        logging.warning("Novel_architecture.txt is empty.")
        return

    llm_adapter = create_llm_adapter(
        interface_format=interface_format,
        base_url=base_url,
        model_name=llm_model,
        api_key=api_key,
        temperature=temperature,
        max_tokens=max_tokens,
        timeout=timeout
    )

    filename_dir = os.path.join(filepath, "Novel_directory.txt")
    if not os.path.exists(filename_dir):
        open(filename_dir, "w", encoding="utf-8").close()

    # è¯»å–å·²æœ‰ç›®å½•ä½œä¸ºä¸Šä¸‹æ–‡
    existing_blueprint = read_file(filename_dir)
    if existing_blueprint:
        existing_blueprint = existing_blueprint.strip()
    else:
        existing_blueprint = ""

    # è®¡ç®—åˆ†å—å¤§å°
    chunk_size = compute_chunk_size(end_chapter - start_chapter + 1, max_tokens)
    logging.info(f"Generating chapters [{start_chapter}..{end_chapter}], computed chunk_size = {chunk_size}.")

    # ========== å…³é”®ä¿®å¤ï¼šä½¿ç”¨ parse_blueprint_blocks è§£æå·²æœ‰ç›®å½• ==========
    # åˆ†ç¦»å·²æœ‰ç›®å½•ä¸­çš„å•å…ƒå’Œç« èŠ‚
    existing_units, existing_chapter_blocks = parse_blueprint_blocks(existing_blueprint)
    
    if existing_units:
        logging.info(f"Found {len(existing_units)} existing units to preserve.")
    if existing_chapter_blocks:
        logging.info(f"Found {len(existing_chapter_blocks)} existing chapters.")

    # ========== ç¬¬ä¸€é˜¶æ®µï¼šæ£€æŸ¥å¹¶ç”Ÿæˆå•å…ƒä¿¡æ¯ ==========
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸ºå½“å‰ç”ŸæˆèŒƒå›´ç”Ÿæˆæ–°çš„å•å…ƒä¿¡æ¯
    def get_unit_chapter_range(unit_text):
        """è·å–å•å…ƒçš„ç« èŠ‚èŒƒå›´"""
        match = re.search(r"ç¬¬\s*(\d+)\s*å•å…ƒ.*?åŒ…å«ç« èŠ‚[ï¼š:]\s*(\d+)\s*[-~è‡³]\s*(\d+)", unit_text, re.DOTALL)
        if match:
            return int(match.group(2)), int(match.group(3))
        return None, None
    
    # æ‰¾å‡ºè¦†ç›–å½“å‰ç”ŸæˆèŒƒå›´çš„å·²æœ‰å•å…ƒ
    units_covering_range = []
    for unit in existing_units:
        unit_start, unit_end = get_unit_chapter_range(unit)
        if unit_start and unit_end:
            # æ£€æŸ¥å•å…ƒæ˜¯å¦ä¸ç”ŸæˆèŒƒå›´æœ‰é‡å 
            if not (unit_end < start_chapter or unit_start > end_chapter):
                units_covering_range.append((unit_start, unit_end, unit))
    
    # åˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆæ–°çš„å•å…ƒä¿¡æ¯
    need_generate_units = False
    if not existing_units:
        # æ²¡æœ‰ä»»ä½•å•å…ƒä¿¡æ¯ï¼Œéœ€è¦ç”Ÿæˆ
        need_generate_units = True
        logging.info("No existing units found. Will generate unit information.")
    else:
        # æ£€æŸ¥ç”ŸæˆèŒƒå›´æ˜¯å¦è¢«å·²æœ‰å•å…ƒå®Œå…¨è¦†ç›–
        covered_chapters = set()
        for unit_start, unit_end, _ in units_covering_range:
            for ch in range(unit_start, unit_end + 1):
                if start_chapter <= ch <= end_chapter:
                    covered_chapters.add(ch)
        
        expected_chapters = set(range(start_chapter, end_chapter + 1))
        uncovered_chapters = expected_chapters - covered_chapters
        
        if uncovered_chapters:
            need_generate_units = True
            logging.info(f"Chapters {sorted(uncovered_chapters)} not covered by existing units. Will generate unit information.")
    
    # å¦‚æœéœ€è¦ç”Ÿæˆå•å…ƒä¿¡æ¯
    if need_generate_units:
        logging.info("Phase 1: Generating unit information...")
        
        try:
            units_result = generate_units_for_range_stream(
                llm_adapter=llm_adapter,
                architecture_text=architecture_text,
                existing_blueprint=existing_blueprint,
                start_chapter=start_chapter,
                end_chapter=end_chapter,
                number_of_chapters=number_of_chapters,
                user_guidance=user_guidance,
                world_building="",  # ä¸–ç•Œè§‚ä¿¡æ¯
                stream_callback=stream_callback
            )
            
            # è§£ææ–°ç”Ÿæˆçš„å•å…ƒä¿¡æ¯
            new_units, _ = parse_blueprint_blocks(units_result)
            
            if new_units:
                logging.info(f"Generated {len(new_units)} new unit(s).")
                
                # åˆå¹¶æ–°ç”Ÿæˆçš„å•å…ƒåˆ°å·²æœ‰å•å…ƒä¸­
                for new_unit in new_units:
                    new_unit_start, new_unit_end = get_unit_chapter_range(new_unit)
                    if new_unit_start and new_unit_end:
                        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›¿æ¢å·²æœ‰å•å…ƒ
                        replaced = False
                        for i, existing_unit in enumerate(existing_units):
                            existing_start, existing_end = get_unit_chapter_range(existing_unit)
                            if existing_start and existing_end:
                                # å¦‚æœæ–°å•å…ƒä¸å·²æœ‰å•å…ƒæœ‰é‡å ï¼Œæ›¿æ¢å·²æœ‰å•å…ƒ
                                if not (new_unit_end < existing_start or new_unit_start > existing_end):
                                    existing_units[i] = new_unit.strip()
                                    replaced = True
                                    logging.info(f"Replaced unit covering chapters {existing_start}-{existing_end} with new unit covering {new_unit_start}-{new_unit_end}")
                                    break
                        
                        if not replaced:
                            # æ–°å¢å•å…ƒ
                            existing_units.append(new_unit.strip())
                            logging.info(f"Added new unit covering chapters {new_unit_start}-{new_unit_end}")
                
                # æŒ‰å•å…ƒç¼–å·æ’åº
                def get_unit_number(unit_text):
                    match = re.search(r"ç¬¬\s*(\d+)\s*å•å…ƒ", unit_text)
                    return int(match.group(1)) if match else 0
                
                existing_units.sort(key=get_unit_number)
                logging.info(f"Units sorted: {[get_unit_number(u) for u in existing_units]}")
        
        except Exception as e:
            logging.error(f"Failed to generate unit information: {e}")
            if stream_callback:
                stream_callback(f"\n\nâš ï¸ å•å…ƒä¿¡æ¯ç”Ÿæˆå¤±è´¥ï¼š{e}ï¼Œå°†ä½¿ç”¨å·²æœ‰å•å…ƒä¿¡æ¯ç»§ç»­ç”Ÿæˆç« èŠ‚ã€‚\n\n")

    # åˆ†ç¦»å‡ºä¸åœ¨ç”ŸæˆèŒƒå›´å†…çš„ç« èŠ‚
    before_chapters = []   # èµ·å§‹ç« èŠ‚ä¹‹å‰çš„ç« èŠ‚
    after_chapters = []    # ç»“æŸç« èŠ‚ä¹‹åçš„ç« èŠ‚
    in_range_chapters = {} # ç”ŸæˆèŒƒå›´å†…çš„å·²æœ‰ç« èŠ‚ï¼ˆç« èŠ‚å· -> ç« èŠ‚æ–‡æœ¬ï¼‰

    for chapter_text in existing_chapter_blocks:
        # æ¸…ç†ç« èŠ‚å†…å®¹
        chapter_text = chapter_text.strip()
        while chapter_text.startswith("**"):
            chapter_text = chapter_text[2:].lstrip()
        while chapter_text.endswith("**"):
            chapter_text = chapter_text[:-2].rstrip()

        match = re.search(r"ç¬¬\s*(\d+)\s*ç« ", chapter_text)
        if match:
            chapter_num = int(match.group(1))
            if chapter_num < start_chapter:
                before_chapters.append(chapter_text)
            elif chapter_num > end_chapter:
                after_chapters.append(chapter_text)
            else:
                in_range_chapters[chapter_num] = chapter_text

    # å¾ªç¯ç”ŸæˆæŒ‡å®šèŒƒå›´å†…çš„ç« èŠ‚
    current_start = start_chapter
    current_chunk = 0

    # é€šçŸ¥å¼€å§‹ç”Ÿæˆç« èŠ‚
    if stream_callback:
        stream_callback("\n\n========== ã€ç¬¬äºŒé˜¶æ®µï¼šç”Ÿæˆç« èŠ‚ä¿¡æ¯ã€‘ ==========\n\n")

    while current_start <= end_chapter:
        current_end = min(current_start + chunk_size - 1, end_chapter)

        # è·å–ä¸Šä¸‹æ–‡ç›®å½•ï¼ˆé™åˆ¶ä¸ºæœ€è¿‘100ç« ï¼‰
        # åŒ…å«ï¼šæ‰€æœ‰å•å…ƒä¿¡æ¯ + èµ·å§‹ç« èŠ‚ä¹‹å‰çš„ç« èŠ‚ + ç”ŸæˆèŒƒå›´å†…çš„å·²æœ‰ç« èŠ‚ + ç»“æŸç« èŠ‚ä¹‹åçš„ç« èŠ‚
        context_parts = []
        
        # æ·»åŠ æ‰€æœ‰å•å…ƒä¿¡æ¯ä½œä¸ºä¸Šä¸‹æ–‡
        context_parts.extend(existing_units)
        
        # ========== å…³é”®ä¿®å¤ï¼šæå–æ—©æœŸç« èŠ‚çš„ä¼ç¬”å…ƒæ•°æ® ==========
        # ä»è¢«æˆªæ–­çš„æ—©æœŸç« èŠ‚ä¸­æå–æœªå›æ”¶çš„ä¼ç¬”
        before_chapters_sample = before_chapters[-30:] if len(before_chapters) > 30 else before_chapters
        truncated_before = before_chapters[:-30] if len(before_chapters) > 30 else []
        
        if truncated_before:
            # ä»è¢«æˆªæ–­çš„æ—©æœŸç« èŠ‚ä¸­æå–ä¼ç¬”ä¿¡æ¯
            early_foreshadow = track_foreshadowing(truncated_before)
            if early_foreshadow["unresolved"]:
                # åˆ›å»ºä¼ç¬”æ‘˜è¦
                foreshadow_summary = "ã€æ—©æœŸæœªå›æ”¶ä¼ç¬”æé†’ã€‘\n"
                for item, chapter in early_foreshadow["unresolved"].items():
                    foreshadow_summary += f"- ç¬¬{chapter}ç« åŸ‹è®¾çš„ä¼ç¬”ã€Œ{item}ã€å°šæœªå›æ”¶\n"
                context_parts.append(foreshadow_summary)
                logging.info(f"ä»æ—©æœŸç« èŠ‚æå–äº†{len(early_foreshadow['unresolved'])}ä¸ªæœªå›æ”¶ä¼ç¬”")
        
        # æ·»åŠ ç« èŠ‚ä¸Šä¸‹æ–‡
        in_range_chapters_list = [text for num, text in sorted(in_range_chapters.items())]
        after_chapters_sample = after_chapters[-50:] if after_chapters else []
        context_parts.extend(before_chapters_sample)
        context_parts.extend(in_range_chapters_list)
        context_parts.extend(after_chapters_sample)
        
        context_blueprint = "\n\n".join(context_parts)
        limited_blueprint = limit_chapter_blueprint(context_blueprint, 100)

        # æ„å»ºæç¤ºè¯
        # æ„å»ºå•å…ƒä¿¡æ¯å­—ç¬¦ä¸²
        unit_info = "\n\n".join(existing_units)
        
        chunk_prompt = chunked_chapter_blueprint_prompt.format(
            novel_architecture=architecture_text,
            chapter_list=limited_blueprint,
            number_of_chapters=number_of_chapters,
            n=current_start,
            m=current_end,
            user_guidance=user_guidance,
            generation_requirements=generation_requirements if generation_requirements else "æ— ç‰¹æ®Šè¦æ±‚",
            world_building="",
            unit_info=unit_info
        )

        logging.info(f"Generating chapters [{current_start}..{current_end}] in a chunk...")

        # ç”Ÿæˆç« èŠ‚ç›®å½•ï¼ˆå¸¦æµå¼è¾“å‡ºï¼‰
        chunk_result = invoke_with_streaming(
            llm_adapter, 
            chunk_prompt, 
            stream_callback=stream_callback
        )

        if not chunk_result or not chunk_result.strip():
            error_msg = f"ç« èŠ‚ [{current_start}..{current_end}] ç”Ÿæˆå¤±è´¥ï¼šè¿”å›å†…å®¹ä¸ºç©º"
            logging.error(error_msg)
            # ä¿å­˜å·²æœ‰å†…å®¹ï¼ˆåŒ…å«å•å…ƒä¿¡æ¯ï¼‰
            save_parts = _interleave_units_and_chapters(existing_units, before_chapters + [text for _, text in sorted(in_range_chapters.items())] + after_chapters)
            save_blueprint = "\n\n".join(save_parts).strip()
            clear_file_content(filename_dir)
            save_string_to_txt(save_blueprint, filename_dir)
            if stream_callback:
                stream_callback(f"\n\nâŒ {error_msg}")
            raise ValueError(error_msg)

        # æ¸…ç†æ–°ç”Ÿæˆçš„å†…å®¹
        cleaned_result = chunk_result.strip()
        if cleaned_result.startswith("##"):
            cleaned_result = cleaned_result[2:].lstrip()
        while cleaned_result.startswith("\n"):
            cleaned_result = cleaned_result[1:]

        # ========== å…³é”®ä¿®å¤ï¼šä½¿ç”¨ parse_blueprint_blocks è§£ææ–°ç”Ÿæˆçš„å†…å®¹ ==========
        new_units, new_chapter_blocks = parse_blueprint_blocks(cleaned_result)
        
        if new_units:
            logging.info(f"New generation contains {len(new_units)} unit(s).")
        if new_chapter_blocks:
            logging.info(f"New generation contains {len(new_chapter_blocks)} chapter(s).")

        # å¤„ç†æ–°ç”Ÿæˆçš„å•å…ƒä¿¡æ¯
        # å°†æ–°ç”Ÿæˆçš„å•å…ƒåˆå¹¶åˆ°å·²æœ‰å•å…ƒä¸­ï¼ˆæ›¿æ¢æˆ–æ–°å¢ï¼‰
        for new_unit in new_units:
            new_unit_match = re.search(r"ç¬¬\s*(\d+)\s*å•å…ƒ", new_unit)
            if new_unit_match:
                new_unit_num = int(new_unit_match.group(1))
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åŒç¼–å·çš„å•å…ƒ
                replaced = False
                for i, existing_unit in enumerate(existing_units):
                    existing_unit_match = re.search(r"ç¬¬\s*(\d+)\s*å•å…ƒ", existing_unit)
                    if existing_unit_match and int(existing_unit_match.group(1)) == new_unit_num:
                        # æ›¿æ¢å·²æœ‰å•å…ƒ
                        existing_units[i] = new_unit.strip()
                        replaced = True
                        logging.info(f"Replaced existing unit {new_unit_num} with new content.")
                        break
                if not replaced:
                    # æ–°å¢å•å…ƒ
                    existing_units.append(new_unit.strip())
                    logging.info(f"Added new unit {new_unit_num}.")
        
        # ========== å…³é”®ä¿®å¤ï¼šæŒ‰å•å…ƒç¼–å·æ’åº ==========
        def get_unit_number(unit_text):
            match = re.search(r"ç¬¬\s*(\d+)\s*å•å…ƒ", unit_text)
            return int(match.group(1)) if match else 0
        
        existing_units.sort(key=get_unit_number)
        logging.info(f"Units sorted: {[get_unit_number(u) for u in existing_units]}")

        # å¤„ç†æ–°ç”Ÿæˆçš„ç« èŠ‚
        for new_chapter in new_chapter_blocks:
            new_chapter = new_chapter.strip()
            while new_chapter.startswith("**"):
                new_chapter = new_chapter[2:].lstrip()
            while new_chapter.endswith("**"):
                new_chapter = new_chapter[:-2].rstrip()

            new_match = re.search(r"ç¬¬\s*(\d+)\s*ç« ", new_chapter)
            if new_match:
                new_chapter_num = int(new_match.group(1))
                if new_chapter_num <= 0:
                    logging.warning(f"æ— æ•ˆçš„ç« èŠ‚å·ï¼š{new_chapter_num}ï¼Œè·³è¿‡è¯¥ç« èŠ‚")
                    continue
                if start_chapter <= new_chapter_num <= end_chapter:
                    # ========== ä¿®ä¸ºæ ¡éªŒï¼šæŸ¥æ‰¾ç« èŠ‚å¯¹åº”çš„å•å…ƒä¿¡æ¯ ==========
                    # æ‰¾åˆ°ç« èŠ‚æ‰€å±çš„å•å…ƒ
                    chapter_unit = None
                    for unit in existing_units:
                        # åŒ¹é…å•å…ƒçš„ç« èŠ‚èŒƒå›´ï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼š
                        # æ ¼å¼1: åŒ…å«ç« èŠ‚ï¼š1-3ç« 
                        # æ ¼å¼2: ç« èŠ‚èŒƒå›´ï¼š1-3
                        unit_match = re.search(r"(?:åŒ…å«ç« èŠ‚|ç« èŠ‚èŒƒå›´)[ï¼š:]\s*(\d+)\s*[-~è‡³]\s*(\d+)", unit, re.DOTALL)
                        if unit_match:
                            unit_start = int(unit_match.group(1))
                            unit_end = int(unit_match.group(2))
                            if unit_start <= new_chapter_num <= unit_end:
                                chapter_unit = unit
                                break
                    
                    # å¦‚æœæ‰¾åˆ°å¯¹åº”å•å…ƒï¼Œè¿›è¡Œä¿®ä¸ºæ ¡éªŒ
                    if chapter_unit:
                        original_chapter = new_chapter
                        new_chapter = validate_and_fix_cultivation_progression(chapter_unit, new_chapter)
                        if new_chapter != original_chapter:
                            logging.info(f"ç« èŠ‚ {new_chapter_num} ä¿®ä¸ºå·²æ ¡éªŒä¿®æ­£")
                        
                        # ========== ç©ºé—´åæ ‡æ ¡éªŒ ==========
                        is_valid, warning = validate_spatial_coordinates(chapter_unit, new_chapter)
                        if not is_valid:
                            logging.warning(f"ç« èŠ‚ {new_chapter_num} ç©ºé—´åæ ‡æ ¡éªŒå¤±è´¥ï¼š{warning}")
                            if stream_callback:
                                stream_callback(f"\n\nâš ï¸ ç©ºé—´åæ ‡è­¦å‘Šï¼šç¬¬{new_chapter_num}ç«  {warning}")
                    
                    if new_chapter_num not in in_range_chapters:
                        in_range_chapters[new_chapter_num] = new_chapter
                    # å¦‚æœå·²å­˜åœ¨ï¼Œä¿ç•™åŸæœ‰å†…å®¹ï¼ˆä¸è¦†ç›–ï¼‰

        # ========== å…³é”®ä¿®å¤ï¼šæ„å»º final_blueprint æ—¶åŒ…å«å•å…ƒä¿¡æ¯ ==========
        # åˆå¹¶æ‰€æœ‰ç« èŠ‚
        all_chapter_texts = []
        for text in before_chapters:
            match = re.search(r"ç¬¬\s*(\d+)\s*ç« ", text)
            if match:
                all_chapter_texts.append(text)
        
        for chapter_num, text in sorted(in_range_chapters.items()):
            all_chapter_texts.append(text)
        
        for text in after_chapters:
            match = re.search(r"ç¬¬\s*(\d+)\s*ç« ", text)
            if match:
                all_chapter_texts.append(text)

        # ä½¿ç”¨ _interleave_units_and_chapters æŒ‰æ­£ç¡®é¡ºåºæ’åˆ—å•å…ƒå’Œç« èŠ‚
        final_parts = _interleave_units_and_chapters(existing_units, all_chapter_texts)
        final_blueprint = "\n\n".join(final_parts)

        # ========== ç« èŠ‚è¿ç»­æ€§æ ¡éªŒ ==========
        # æ ¡éªŒå½“å‰ç”ŸæˆèŒƒå›´å†…çš„ç« èŠ‚æ˜¯å¦è¿ç»­
        in_range_chapter_texts = [text for _, text in sorted(in_range_chapters.items())]
        is_valid, missing, duplicate = validate_chapter_continuity(
            in_range_chapter_texts, current_start, current_end
        )
        
        if not is_valid:
            if missing:
                warning_msg = f"âš ï¸ ç« èŠ‚è¿ç»­æ€§è­¦å‘Šï¼šç¼ºå¤±ç« èŠ‚ {missing}"
                logging.warning(warning_msg)
                if stream_callback:
                    stream_callback(f"\n\n{warning_msg}")
            if duplicate:
                warning_msg = f"âš ï¸ ç« èŠ‚è¿ç»­æ€§è­¦å‘Šï¼šé‡å¤ç« èŠ‚ {duplicate}"
                logging.warning(warning_msg)
                if stream_callback:
                    stream_callback(f"\n\n{warning_msg}")

        # æ¯æ¬¡ç”Ÿæˆå®Œä¸€ä¸ªåˆ†å—åéƒ½ä¿å­˜åˆ°æ–‡ä»¶
        clear_file_content(filename_dir)
        save_string_to_txt(final_blueprint.strip(), filename_dir)

        current_chunk += 1
        current_start = current_end + 1

    # ========== ä¼ç¬”è¿½è¸ªæ ¡éªŒ ==========
    # å¯¹æ‰€æœ‰ç« èŠ‚è¿›è¡Œä¼ç¬”è¿½è¸ª
    all_chapters_for_tracking = []
    for text in before_chapters:
        all_chapters_for_tracking.append(text)
    for chapter_num, text in sorted(in_range_chapters.items()):
        all_chapters_for_tracking.append(text)
    for text in after_chapters:
        all_chapters_for_tracking.append(text)
    
    foreshadow_tracking = track_foreshadowing(all_chapters_for_tracking)
    
    if foreshadow_tracking["warnings"]:
        logging.warning("ä¼ç¬”è¿½è¸ªå‘ç°ä»¥ä¸‹é—®é¢˜ï¼š")
        for warning in foreshadow_tracking["warnings"]:
            logging.warning(f"  - {warning}")
            if stream_callback:
                stream_callback(f"\n\nâš ï¸ ä¼ç¬”è­¦å‘Šï¼š{warning}")
    
    if foreshadow_tracking["unresolved"]:
        unresolved_info = f"ğŸ“‹ æœªå›æ”¶ä¼ç¬”ç»Ÿè®¡ï¼šå…±{len(foreshadow_tracking['unresolved'])}ä¸ª"
        logging.info(unresolved_info)
        for item, chapter in foreshadow_tracking["unresolved"].items():
            logging.info(f"  - ã€Œ{item}ã€åŸ‹è®¾äºç¬¬{chapter}ç« ")

    logging.info(f"Chapters [{start_chapter}..{end_chapter}] blueprint have been generated successfully.")
    logging.info(f"Final blueprint contains {len(existing_units)} units and {len(in_range_chapters) + len(before_chapters) + len(after_chapters)} chapters.")

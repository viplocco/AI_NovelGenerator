#novel_generator/vectorstore_utils.py
# -*- coding: utf-8 -*-
"""
å‘é‡åº“ç›¸å…³æ“ä½œï¼ˆåˆå§‹åŒ–ã€æ›´æ–°ã€æ£€ç´¢ã€æ¸…ç©ºã€æ–‡æœ¬åˆ‡åˆ†ç­‰ï¼‰
"""
import os
import logging
import traceback
import nltk
import numpy as np
import re
import ssl
import requests
import warnings
from langchain_chroma import Chroma

# ç¦ç”¨ç‰¹å®šçš„Torchè­¦å‘Š
warnings.filterwarnings('ignore', message='.*Torch was not compiled with flash attention.*')
os.environ["TOKENIZERS_PARALLELISM"] = "false"  # ç¦ç”¨tokenizerå¹¶è¡Œè­¦å‘Š

from chromadb.config import Settings
try:
    from langchain_core.documents import Document
except ImportError:
    from langchain.docstore.document import Document  # type: ignore
from sklearn.metrics.pairwise import cosine_similarity
from .common import call_with_retry

def get_vectorstore_dir(filepath: str) -> str:
    """è·å– vectorstore è·¯å¾„"""
    return os.path.join(filepath, "vectorstore")

def clear_vector_store(filepath: str) -> bool:
    """æ¸…ç©º æ¸…ç©ºå‘é‡åº“"""
    import shutil
    store_dir = get_vectorstore_dir(filepath)
    if not os.path.exists(store_dir):
        logging.info("No vector store found to clear.")
        return False
    try:
        shutil.rmtree(store_dir)
        logging.info(f"Vector store directory '{store_dir}' removed.")
        return True
    except Exception as e:
        logging.error(f"æ— æ³•åˆ é™¤å‘é‡åº“æ–‡ä»¶å¤¹ï¼Œè¯·å…³é—­ç¨‹åºåæ‰‹åŠ¨åˆ é™¤ {store_dir}ã€‚\n {str(e)}")
        traceback.print_exc()
        return False

def init_vector_store(embedding_adapter, texts, filepath: str):
    """
    åœ¨ filepath ä¸‹åˆ›å»º/åŠ è½½ä¸€ä¸ª Chroma å‘é‡åº“å¹¶æ’å…¥ textsã€‚
    å¦‚æœEmbeddingå¤±è´¥ï¼Œåˆ™è¿”å› Noneï¼Œä¸ä¸­æ–­ä»»åŠ¡ã€‚
    """
    try:
        from langchain_core.embeddings import Embeddings as LCEmbeddings
    except ImportError:
        from langchain.embeddings.base import Embeddings as LCEmbeddings

    store_dir = get_vectorstore_dir(filepath)
    os.makedirs(store_dir, exist_ok=True)
    documents = [Document(page_content=str(t)) for t in texts]

    try:
        class LCEmbeddingWrapper(LCEmbeddings):
            def embed_documents(self, texts):
                return call_with_retry(
                    func=embedding_adapter.embed_documents,
                    max_retries=3,
                    fallback_return=[],
                    texts=texts
                )
            def embed_query(self, query: str):
                res = call_with_retry(
                    func=embedding_adapter.embed_query,
                    max_retries=3,
                    fallback_return=[],
                    query=query
                )
                return res

        chroma_embedding = LCEmbeddingWrapper()
        vectorstore = Chroma.from_documents(
            documents,
            embedding=chroma_embedding,
            persist_directory=store_dir,
            client_settings=Settings(anonymized_telemetry=False),
            collection_name="novel_collection"
        )
        return vectorstore
    except Exception as e:
        logging.warning(f"Init vector store failed: {e}")
        traceback.print_exc()
        return None

def load_vector_store(embedding_adapter, filepath: str):
    """
    è¯»å–å·²å­˜åœ¨çš„ Chroma å‘é‡åº“ã€‚è‹¥ä¸å­˜åœ¨åˆ™è¿”å› Noneã€‚
    å¦‚æœåŠ è½½å¤±è´¥ï¼ˆembedding æˆ–IOé—®é¢˜ï¼‰ï¼Œåˆ™è¿”å› Noneã€‚
    """
    try:
        from langchain_core.embeddings import Embeddings as LCEmbeddings
    except ImportError:
        from langchain.embeddings.base import Embeddings as LCEmbeddings
    store_dir = get_vectorstore_dir(filepath)
    if not os.path.exists(store_dir):
        logging.info("Vector store not found. Will return None.")
        return None

    try:
        class LCEmbeddingWrapper(LCEmbeddings):
            def embed_documents(self, texts):
                return call_with_retry(
                    func=embedding_adapter.embed_documents,
                    max_retries=3,
                    fallback_return=[],
                    texts=texts
                )
            def embed_query(self, query: str):
                res = call_with_retry(
                    func=embedding_adapter.embed_query,
                    max_retries=3,
                    fallback_return=[],
                    query=query
                )
                return res

        chroma_embedding = LCEmbeddingWrapper()
        return Chroma(
            persist_directory=store_dir,
            embedding_function=chroma_embedding,
            client_settings=Settings(anonymized_telemetry=False),
            collection_name="novel_collection"
        )
    except Exception as e:
        logging.warning(f"Failed to load vector store: {e}")
        traceback.print_exc()
        return None

def split_by_length(text: str, max_length: int = 500):
    """æŒ‰ç…§ max_length åˆ‡åˆ†æ–‡æœ¬"""
    segments = []
    start_idx = 0
    while start_idx < len(text):
        end_idx = min(start_idx + max_length, len(text))
        segment = text[start_idx:end_idx]
        segments.append(segment.strip())
        start_idx = end_idx
    return segments

def split_text_for_vectorstore(chapter_text: str, max_length: int = 500, similarity_threshold: float = 0.7):
    """
    å¯¹æ–°çš„ç« èŠ‚æ–‡æœ¬è¿›è¡Œåˆ†æ®µå,å†ç”¨äºå­˜å…¥å‘é‡åº“ã€‚
    ä½¿ç”¨ embedding è¿›è¡Œæ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ã€‚
    """
    if not chapter_text.strip():
        return []
    
    nltk.download('punkt', quiet=True)
    nltk.download('punkt_tab', quiet=True)
    sentences = nltk.sent_tokenize(chapter_text)
    if not sentences:
        return []
    
    # ç›´æ¥æŒ‰é•¿åº¦åˆ†æ®µ,ä¸åšç›¸ä¼¼åº¦åˆå¹¶
    final_segments = []
    current_segment = []
    current_length = 0
    
    for sentence in sentences:
        sentence_length = len(sentence)
        if current_length + sentence_length > max_length:
            if current_segment:
                final_segments.append(" ".join(current_segment))
            current_segment = [sentence]
            current_length = sentence_length
        else:
            current_segment.append(sentence)
            current_length += sentence_length
    
    if current_segment:
        final_segments.append(" ".join(current_segment))
    
    return final_segments

def update_vector_store(embedding_adapter, new_chapter: str, filepath: str):
    """
    å°†æœ€æ–°ç« èŠ‚æ–‡æœ¬æ’å…¥åˆ°å‘é‡åº“ä¸­ã€‚
    è‹¥åº“ä¸å­˜åœ¨åˆ™åˆå§‹åŒ–ï¼›è‹¥åˆå§‹åŒ–/æ›´æ–°å¤±è´¥ï¼Œåˆ™è·³è¿‡ã€‚
    è¿”å›å€¼ï¼šæˆåŠŸæ—¶è¿”å›æ›´æ–°çš„æ•°æ®æ¡æ•°ï¼Œå¤±è´¥æ—¶è¿”å›0
    """
    from utils import read_file, clear_file_content, save_string_to_txt
    splitted_texts = split_text_for_vectorstore(new_chapter)
    if not splitted_texts:
        logging.warning("No valid text to insert into vector store. Skipping.")
        return 0

    logging.info(f"ğŸ“ ç« èŠ‚æ–‡æœ¬å·²åˆ†æ®µï¼Œå…±{len(splitted_texts)}æ®µ")
    
    store = load_vector_store(embedding_adapter, filepath)
    if not store:
        logging.info("Vector store does not exist or failed to load. Initializing a new one for new chapter...")
        store = init_vector_store(embedding_adapter, splitted_texts, filepath)
        if not store:
            logging.warning("Init vector store failed, skip embedding.")
            return 0
        else:
            logging.info(f"âœ“ æ–°å‘é‡åº“åˆ›å»ºæˆåŠŸï¼Œå…±æ’å…¥{len(splitted_texts)}æ¡æ•°æ®")
            return len(splitted_texts)

    try:
        docs = [Document(page_content=str(t)) for t in splitted_texts]
        store.add_documents(docs)
        logging.info(f"âœ“ å‘é‡åº“æ›´æ–°æˆåŠŸï¼Œæœ¬æ¬¡æ›´æ–°{len(docs)}æ¡æ•°æ®")
        return len(docs)
    except Exception as e:
        logging.warning(f"Failed to update vector store: {e}")
        traceback.print_exc()
        return 0

def get_relevant_context_from_vector_store(embedding_adapter, query: str, filepath: str, k: int = 2) -> str:
    """
    ä»å‘é‡åº“ä¸­æ£€ç´¢ä¸ query æœ€ç›¸å…³çš„ k æ¡æ–‡æœ¬ï¼Œæ‹¼æ¥åè¿”å›ã€‚
    å¦‚æœå‘é‡åº“åŠ è½½/æ£€ç´¢å¤±è´¥ï¼Œåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚
    æœ€ç»ˆåªè¿”å›æœ€å¤š2000å­—ç¬¦çš„æ£€ç´¢ç‰‡æ®µã€‚
    """
    store = load_vector_store(embedding_adapter, filepath)
    if not store:
        logging.info("No vector store found or load failed. Returning empty context.")
        return ""

    try:
        docs = store.similarity_search(query, k=k)
        if not docs:
            logging.info(f"No relevant documents found for query '{query}'. Returning empty context.")
            return ""
        combined = "\n".join([d.page_content for d in docs])
        if len(combined) > 2000:
            combined = combined[:2000]
        return combined
    except Exception as e:
        logging.warning(f"Similarity search failed: {e}")
        traceback.print_exc()
        return ""

def _get_sentence_transformer(model_name: str = 'paraphrase-MiniLM-L6-v2'):
    """è·å–sentence transformeræ¨¡å‹ï¼Œå¤„ç†SSLé—®é¢˜"""
    try:
        # è®¾ç½®torchç¯å¢ƒå˜é‡
        os.environ["TORCH_ALLOW_TF32_CUBLAS_OVERRIDE"] = "0"
        os.environ["TORCH_CUDNN_V8_API_ENABLED"] = "0"
        
        # ç¦ç”¨SSLéªŒè¯
        ssl._create_default_https_context = ssl._create_unverified_context
        
        # ...existing code...
    except Exception as e:
        logging.error(f"Failed to load sentence transformer model: {e}")
        traceback.print_exc()
        return None
